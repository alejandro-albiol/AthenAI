{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b46782bc",
   "metadata": {},
   "source": [
    "# Enhanced Workout Generation Model Training V2\n",
    "Building on successful V1 with more power and better structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d357671",
   "metadata": {},
   "source": [
    "## Setup and Installation (Same as V1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9408b17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install transformers datasets torch accelerate peft bitsandbytes kaggle requests tqdm\n",
    "!pip install --upgrade huggingface_hub\n",
    "\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import requests\n",
    "import zipfile\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForSeq2SeqLM,  # T5 model type\n",
    "    TrainingArguments, \n",
    "    Trainer,\n",
    "    DataCollatorForSeq2Seq\n",
    ")\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f2378c",
   "metadata": {},
   "source": [
    "## Enhanced Memory Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89d521b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup_memory():\n",
    "    \"\"\"Enhanced memory cleanup\"\"\"\n",
    "    import gc\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.synchronize()\n",
    "    print(\"ğŸ§¹ Memory cleanup completed\")\n",
    "    \n",
    "def print_gpu_utilization():\n",
    "    \"\"\"Print current GPU memory usage\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        allocated = torch.cuda.memory_allocated() / 1024**3\n",
    "        reserved = torch.cuda.memory_reserved() / 1024**3\n",
    "        free = torch.cuda.get_device_properties(0).total_memory / 1024**3 - reserved\n",
    "        print(f\"ğŸ“Š GPU - Used: {allocated:.2f}GB, Reserved: {reserved:.2f}GB, Free: {free:.2f}GB\")\n",
    "    else:\n",
    "        print(\"ğŸ“Š No GPU available\")\n",
    "\n",
    "print(\"Initial GPU state:\")\n",
    "print_gpu_utilization()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7ae6ba",
   "metadata": {},
   "source": [
    "## Data Loading (Enhanced - from your successful V1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44d12f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use your existing data loading functions but enhanced\n",
    "def download_and_load_data():\n",
    "    \"\"\"Load both datasets efficiently\"\"\"\n",
    "    \n",
    "    # GitHub exercises (from V1)\n",
    "    def download_github_exercises():\n",
    "        url = \"https://github.com/yuhonas/free-exercise-db/archive/main.zip\"\n",
    "        response = requests.get(url)\n",
    "        \n",
    "        with open(\"exercise_db.zip\", \"wb\") as f:\n",
    "            f.write(response.content)\n",
    "        \n",
    "        with zipfile.ZipFile(\"exercise_db.zip\", 'r') as zip_ref:\n",
    "            zip_ref.extractall(\"./\")\n",
    "        \n",
    "        exercises_path = \"./free-exercise-db-main/exercises\"\n",
    "        exercises = []\n",
    "        \n",
    "        for file in os.listdir(exercises_path):\n",
    "            if file.endswith('.json'):\n",
    "                with open(os.path.join(exercises_path, file), 'r') as f:\n",
    "                    exercise = json.load(f)\n",
    "                    exercises.append(exercise)\n",
    "        \n",
    "        return exercises\n",
    "    \n",
    "    github_exercises = download_github_exercises()\n",
    "    print(f\"âœ… Loaded {len(github_exercises)} GitHub exercises\")\n",
    "    \n",
    "    # Kaggle dataset (optional)\n",
    "    kaggle_exercises = None\n",
    "    if os.path.exists('gym_exercise_data.csv'):  # If you uploaded it\n",
    "        kaggle_exercises = pd.read_csv('gym_exercise_data.csv')\n",
    "        print(f\"âœ… Loaded {len(kaggle_exercises)} Kaggle exercises\")\n",
    "    \n",
    "    return github_exercises, kaggle_exercises\n",
    "\n",
    "github_exercises, kaggle_exercises = download_and_load_data()\n",
    "cleanup_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e890b7",
   "metadata": {},
   "source": [
    "## Enhanced Training Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc079538",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_enhanced_training_data(github_exercises, kaggle_exercises=None, num_samples=200):\n",
    "    \"\"\"Create high-quality, diverse training data matching your database schema\"\"\"\n",
    "    \n",
    "    # Standardize exercises first\n",
    "    def standardize_exercise_data(github_ex, kaggle_df=None):\n",
    "        standardized = []\n",
    "        \n",
    "        for ex in github_ex:\n",
    "            standardized_ex = {\n",
    "                'name': ex.get('name', ''),\n",
    "                'difficulty_level': ex.get('level', 'beginner'),\n",
    "                'exercise_type': ex.get('category', 'strength'),\n",
    "                'primary_muscles': ex.get('primaryMuscles', []),\n",
    "                'secondary_muscles': ex.get('secondaryMuscles', []),\n",
    "                'equipment': ex.get('equipment', ''),\n",
    "                'instructions': ' '.join(ex.get('instructions', [])),\n",
    "                'force_type': ex.get('force', ''),\n",
    "                'mechanic': ex.get('mechanic', '')\n",
    "            }\n",
    "            standardized.append(standardized_ex)\n",
    "        \n",
    "        return standardized\n",
    "    \n",
    "    exercises = standardize_exercise_data(github_exercises, kaggle_exercises)\n",
    "    \n",
    "    # Enhanced user profiles matching your database\n",
    "    user_profiles = [\n",
    "        {\n",
    "            'training_phase': 'weight_loss',\n",
    "            'motivation': 'self_improvement',\n",
    "            'special_situation': 'none',\n",
    "            'description': 'Beginner focused on losing weight',\n",
    "            'duration': 30,\n",
    "            'difficulty': 'beginner'\n",
    "        },\n",
    "        {\n",
    "            'training_phase': 'muscle_gain',\n",
    "            'motivation': 'self_improvement',\n",
    "            'special_situation': 'none',\n",
    "            'description': 'Intermediate athlete building muscle',\n",
    "            'duration': 45,\n",
    "            'difficulty': 'intermediate'\n",
    "        },\n",
    "        {\n",
    "            'training_phase': 'muscle_gain',\n",
    "            'motivation': 'competition',\n",
    "            'special_situation': 'none',\n",
    "            'description': 'Advanced lifter preparing for competition',\n",
    "            'duration': 60,\n",
    "            'difficulty': 'advanced'\n",
    "        },\n",
    "        {\n",
    "            'training_phase': 'cardio_improve',\n",
    "            'motivation': 'wellbeing',\n",
    "            'special_situation': 'none',\n",
    "            'description': 'Runner improving cardiovascular fitness',\n",
    "            'duration': 40,\n",
    "            'difficulty': 'intermediate'\n",
    "        },\n",
    "        {\n",
    "            'training_phase': 'maintenance',\n",
    "            'motivation': 'medical_recommendation',\n",
    "            'special_situation': 'elderly_population',\n",
    "            'description': 'Senior maintaining health and mobility',\n",
    "            'duration': 25,\n",
    "            'difficulty': 'beginner'\n",
    "        },\n",
    "        {\n",
    "            'training_phase': 'weight_loss',\n",
    "            'motivation': 'medical_recommendation',\n",
    "            'special_situation': 'post_partum',\n",
    "            'description': 'New mother returning to fitness',\n",
    "            'duration': 20,\n",
    "            'difficulty': 'beginner'\n",
    "        },\n",
    "        {\n",
    "            'training_phase': 'muscle_gain',\n",
    "            'motivation': 'rehabilitation',\n",
    "            'special_situation': 'injury_recovery',\n",
    "            'description': 'Athlete recovering from injury',\n",
    "            'duration': 35,\n",
    "            'difficulty': 'beginner'\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    # Workout block types matching your database\n",
    "    block_types = {\n",
    "        'warmup': {'duration': 5, 'exercises': 2},\n",
    "        'main': {'duration': 25, 'exercises': 4},\n",
    "        'core': {'duration': 8, 'exercises': 3},\n",
    "        'cardio': {'duration': 10, 'exercises': 2},\n",
    "        'cooldown': {'duration': 7, 'exercises': 2}\n",
    "    }\n",
    "    \n",
    "    training_data = []\n",
    "    \n",
    "    for profile in user_profiles:\n",
    "        for sample_num in range(num_samples // len(user_profiles)):\n",
    "            # Create structured input prompt\n",
    "            prompt = f\"\"\"Create workout routine:\n",
    "USER_PROFILE: {profile['description']}\n",
    "TRAINING_PHASE: {profile['training_phase']}\n",
    "MOTIVATION: {profile['motivation']}\n",
    "SPECIAL_SITUATION: {profile['special_situation']}\n",
    "DURATION: {profile['duration']} minutes\n",
    "DIFFICULTY: {profile['difficulty']}\n",
    "TARGET_AUDIENCE: {profile['training_phase']}\n",
    "\n",
    "Generate structured workout with blocks: warmup, main, core, cooldown.\"\"\"\n",
    "\n",
    "            # Create structured response matching your database schema\n",
    "            workout_name = f\"{profile['training_phase'].replace('_', ' ').title()} {profile['difficulty'].title()} Routine\"\n",
    "            \n",
    "            response = f\"\"\"WORKOUT_TEMPLATE:\n",
    "name: {workout_name}\n",
    "description: {profile['description']} focused routine\n",
    "difficulty_level: {profile['difficulty']}\n",
    "estimated_duration_minutes: {profile['duration']}\n",
    "target_audience: {profile['training_phase']}\n",
    "\n",
    "TEMPLATE_BLOCKS:\n",
    "Block 1:\n",
    "block_name: Warmup\n",
    "block_type: warmup\n",
    "block_order: 1\n",
    "exercise_count: 2\n",
    "estimated_duration_minutes: 5\n",
    "instructions: Light movement to prepare body for workout\n",
    "\n",
    "Block 2: \n",
    "block_name: Main Training\n",
    "block_type: main\n",
    "block_order: 2\n",
    "exercise_count: 4\n",
    "estimated_duration_minutes: {profile['duration'] - 15}\n",
    "instructions: Primary exercises targeting {profile['training_phase']}\n",
    "\n",
    "Block 3:\n",
    "block_name: Core Strengthening  \n",
    "block_type: core\n",
    "block_order: 3\n",
    "exercise_count: 3\n",
    "estimated_duration_minutes: 8\n",
    "instructions: Core stability and strength exercises\n",
    "\n",
    "Block 4:\n",
    "block_name: Cooldown\n",
    "block_type: cooldown\n",
    "block_order: 4\n",
    "exercise_count: 2\n",
    "estimated_duration_minutes: 5\n",
    "instructions: Stretching and mobility for recovery\n",
    "\n",
    "EXERCISE_SUGGESTIONS:\n",
    "- Focus on {profile['training_phase']} appropriate movements\n",
    "- Match {profile['difficulty']} difficulty level\n",
    "- Consider {profile['special_situation']} requirements\n",
    "- Ensure proper progression and safety\"\"\"\n",
    "\n",
    "            training_data.append({\n",
    "                'prompt': prompt,\n",
    "                'response': response\n",
    "            })\n",
    "    \n",
    "    # Add variations with different focus areas\n",
    "    focus_variations = ['upper_body', 'lower_body', 'full_body', 'push_muscles', 'pull_muscles']\n",
    "    \n",
    "    for focus in focus_variations:\n",
    "        for profile in user_profiles[:3]:  # Use first 3 profiles\n",
    "            prompt = f\"\"\"Create {focus} workout:\n",
    "USER_PROFILE: {profile['description']}\n",
    "FOCUS_AREA: {focus}\n",
    "TRAINING_PHASE: {profile['training_phase']}  \n",
    "DURATION: {profile['duration']} minutes\n",
    "DIFFICULTY: {profile['difficulty']}\"\"\"\n",
    "\n",
    "            response = f\"\"\"WORKOUT_TEMPLATE:\n",
    "name: {focus.replace('_', ' ').title()} {profile['training_phase'].title()}\n",
    "description: {focus} focused {profile['training_phase']} routine\n",
    "difficulty_level: {profile['difficulty']}\n",
    "estimated_duration_minutes: {profile['duration']}\n",
    "target_audience: {profile['training_phase']}\n",
    "\n",
    "FOCUS: {focus} specialization\n",
    "STRUCTURE: Warm-up â†’ {focus} main exercises â†’ Core â†’ Cool-down\n",
    "PROGRESSION: Appropriate for {profile['difficulty']} level\"\"\"\n",
    "\n",
    "            training_data.append({\n",
    "                'prompt': prompt, \n",
    "                'response': response\n",
    "            })\n",
    "    \n",
    "    print(f\"âœ… Generated {len(training_data)} enhanced training examples\")\n",
    "    return training_data\n",
    "\n",
    "# Generate enhanced training data\n",
    "enhanced_training_data = create_enhanced_training_data(github_exercises, kaggle_exercises, 300)\n",
    "cleanup_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdec6f0a",
   "metadata": {},
   "source": [
    "## Enhanced Model Configuration (More Power!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58770e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your successful model but with more training power\n",
    "model_name = \"a-albiol/AthenAI\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "# Enhanced LoRA configuration - More power!\n",
    "lora_config = LoraConfig(\n",
    "    task_type=TaskType.SEQ_2_SEQ_LM,\n",
    "    inference_mode=False,\n",
    "    r=32,  # Increased from 16 - more learning capacity\n",
    "    lora_alpha=64,  # Increased proportionally\n",
    "    lora_dropout=0.1,\n",
    "    target_modules=[\"q\", \"v\", \"o\", \"wi_0\", \"wi_1\", \"wo\"],\n",
    "    bias=\"none\",\n",
    "    use_rslora=False,\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.train()\n",
    "model.enable_input_require_grads()\n",
    "\n",
    "# Check parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"ğŸ“Š Total parameters: {total_params:,}\")\n",
    "print(f\"ğŸ“Š Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"ğŸ“Š Trainable %: {100 * trainable_params / total_params:.2f}%\")\n",
    "\n",
    "cleanup_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728e259a",
   "metadata": {},
   "source": [
    "## Enhanced Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9d9367",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function_enhanced(examples):\n",
    "    \"\"\"Enhanced tokenization with better handling\"\"\"\n",
    "    \n",
    "    inputs = [prompt for prompt in examples['prompt']]\n",
    "    targets = [response for response in examples['response']]\n",
    "    \n",
    "    # Tokenize with optimized settings\n",
    "    model_inputs = tokenizer(\n",
    "        inputs,\n",
    "        truncation=True,\n",
    "        padding=False,\n",
    "        max_length=768,  # Increased context\n",
    "        return_tensors=None\n",
    "    )\n",
    "    \n",
    "    labels = tokenizer(\n",
    "        targets,\n",
    "        truncation=True,\n",
    "        padding=False,\n",
    "        max_length=768,  # Increased output length\n",
    "        return_tensors=None\n",
    "    )\n",
    "    \n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "# Create enhanced dataset\n",
    "train_dataset = Dataset.from_list(enhanced_training_data)\n",
    "train_dataset = train_dataset.map(\n",
    "    tokenize_function_enhanced,\n",
    "    batched=True,\n",
    "    remove_columns=['prompt', 'response']\n",
    ")\n",
    "\n",
    "print(f\"ğŸ“Š Enhanced dataset size: {len(train_dataset)}\")\n",
    "cleanup_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebadc932",
   "metadata": {},
   "source": [
    "## Enhanced Training Configuration (More Power!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35aaf05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable logging\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "os.environ[\"WANDB_MODE\"] = \"disabled\"\n",
    "\n",
    "# Enhanced training arguments - More power!\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./workout-model-v2-enhanced\",\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=4,  # More epochs!\n",
    "    per_device_train_batch_size=2,  # Slightly larger batch\n",
    "    gradient_accumulation_steps=8,\n",
    "    learning_rate=5e-4,  # Higher learning rate\n",
    "    weight_decay=0.01,\n",
    "    warmup_steps=50,  # Add warmup\n",
    "    logging_steps=25,\n",
    "    save_steps=150,\n",
    "    save_total_limit=3,\n",
    "    prediction_loss_only=True,\n",
    "    remove_unused_columns=False,\n",
    "    dataloader_pin_memory=False,\n",
    "    fp16=True,\n",
    "    report_to=[],\n",
    "    gradient_checkpointing=True,\n",
    "    dataloader_num_workers=2,  # Faster data loading\n",
    "    lr_scheduler_type=\"cosine\",  # Better learning rate schedule\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer=tokenizer,\n",
    "    model=model,\n",
    "    pad_to_multiple_of=8,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "print(\"ğŸš€ Enhanced trainer configured!\")\n",
    "print(f\"ğŸ“Š Training {trainable_params:,} parameters for {training_args.num_train_epochs} epochs\")\n",
    "print(f\"ğŸ“Š Total training steps: ~{len(train_dataset) * training_args.num_train_epochs // (training_args.per_device_train_batch_size * training_args.gradient_accumulation_steps)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a0daca",
   "metadata": {},
   "source": [
    "## Enhanced Training with Monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ee9811",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "print(\"ğŸš€ Starting Enhanced Training...\")\n",
    "print_gpu_utilization()\n",
    "\n",
    "# Verify model before training\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"âœ… Ready to train {trainable_params:,} parameters\")\n",
    "\n",
    "# Start enhanced training\n",
    "start_time = time.time()\n",
    "trainer.train()\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"âœ… Enhanced training completed in {(end_time - start_time) / 60:.1f} minutes\")\n",
    "cleanup_memory()\n",
    "\n",
    "# Save enhanced model\n",
    "trainer.save_model(\"./workout-model-v2-final\")\n",
    "tokenizer.save_pretrained(\"./workout-model-v2-final\")\n",
    "print(\"ğŸ’¾ Enhanced model saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9c3be4",
   "metadata": {},
   "source": [
    "## Enhanced Testing and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af918a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_enhanced_model():\n",
    "    \"\"\"Comprehensive testing of the enhanced model\"\"\"\n",
    "    \n",
    "    def generate_workout_enhanced(prompt):\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\", max_length=768, truncation=True, padding=True)\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            inputs = {k: v.cuda() for k, v in inputs.items()}\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(\n",
    "                input_ids=inputs[\"input_ids\"],\n",
    "                attention_mask=inputs[\"attention_mask\"],\n",
    "                max_new_tokens=600,  # Longer outputs\n",
    "                do_sample=True,\n",
    "                temperature=0.7,\n",
    "                top_p=0.9,\n",
    "                repetition_penalty=1.1,\n",
    "                pad_token_id=tokenizer.pad_token_id,\n",
    "                eos_token_id=tokenizer.eos_token_id\n",
    "            )\n",
    "        \n",
    "        return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    test_cases = [\n",
    "        \"\"\"Create workout routine:\n",
    "USER_PROFILE: Beginner looking to lose weight\n",
    "TRAINING_PHASE: weight_loss\n",
    "MOTIVATION: self_improvement\n",
    "SPECIAL_SITUATION: none\n",
    "DURATION: 30 minutes\n",
    "DIFFICULTY: beginner\n",
    "TARGET_AUDIENCE: weight_loss\"\"\",\n",
    "        \n",
    "        \"\"\"Create upper_body workout:\n",
    "USER_PROFILE: Advanced athlete building muscle\n",
    "FOCUS_AREA: upper_body\n",
    "TRAINING_PHASE: muscle_gain\n",
    "DURATION: 45 minutes\n",
    "DIFFICULTY: advanced\"\"\",\n",
    "        \n",
    "        \"\"\"Create workout routine:\n",
    "USER_PROFILE: Senior maintaining health\n",
    "TRAINING_PHASE: maintenance\n",
    "MOTIVATION: medical_recommendation\n",
    "SPECIAL_SITUATION: elderly_population\n",
    "DURATION: 25 minutes\n",
    "DIFFICULTY: beginner\"\"\"\n",
    "    ]\n",
    "    \n",
    "    print(\"ğŸ§ª Testing Enhanced Model:\")\n",
    "    for i, prompt in enumerate(test_cases, 1):\n",
    "        print(f\"\\n=== Test Case {i} ===\")\n",
    "        try:\n",
    "            response = generate_workout_enhanced(prompt)\n",
    "            print(\"âœ… Generated Response:\")\n",
    "            print(response[:500] + \"...\" if len(response) > 500 else response)\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error: {e}\")\n",
    "\n",
    "# Run enhanced testing\n",
    "test_enhanced_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2723f284",
   "metadata": {},
   "source": [
    "## Summary and Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8c8259",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ‰ Enhanced Training Complete!\")\n",
    "print(f\"ğŸ“Š Model improvements:\")\n",
    "print(f\"   - Increased LoRA rank: 16 â†’ 32 (more learning capacity)\")\n",
    "print(f\"   - More training epochs: 2 â†’ 4\")\n",
    "print(f\"   - Better training data: ~300 structured examples\")\n",
    "print(f\"   - Longer context: 512 â†’ 768 tokens\")\n",
    "print(f\"   - Enhanced prompting aligned with your database schema\")\n",
    "print(f\"   - Cosine learning rate schedule\")\n",
    "\n",
    "print(f\"\\nğŸš€ Expected improvements:\")\n",
    "print(f\"   - Better structured outputs matching your database\")\n",
    "print(f\"   - More diverse workout generation\")\n",
    "print(f\"   - Better understanding of user profiles\")\n",
    "print(f\"   - More professional workout formatting\")\n",
    "\n",
    "print(f\"\\nğŸ’¾ Your enhanced model is saved at: './workout-model-v2-final'\")\n",
    "print(f\"ğŸ”„ Ready to integrate into your Go application!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ed1d78",
   "metadata": {},
   "source": [
    "## Push Enhanced Model to HuggingFace Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f126bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Push enhanced model to HuggingFace Hub\n",
    "from huggingface_hub import login\n",
    "\n",
    "# Login to HuggingFace (use your token)\n",
    "login(ACCESS_TOKEN)\n",
    "\n",
    "# Push model and tokenizer to Hub with v2 tag\n",
    "model.push_to_hub(\"a-albiol/AthenAI\", tags=[\"v2\"])\n",
    "tokenizer.push_to_hub(\"a-albiol/AthenAI\", tags=[\"v2\"])\n",
    "\n",
    "print(\"âœ… Enhanced model (v2) successfully pushed to Hugging Face Hub\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
