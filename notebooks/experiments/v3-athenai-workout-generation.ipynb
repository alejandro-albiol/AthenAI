{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b70e4da",
   "metadata": {},
   "source": [
    "# AthenAI Workout Generation Model Training\n",
    "\n",
    "Fine-tune google/flan-t5-base to generate structured workouts for AthenAI, using user context, workout goals, and template types. Data is mapped to AthenAI backend DTOs. Datasets: [onurSakar/GYM-Exercise](https://huggingface.co/datasets/onurSakar/GYM-Exercise), [Kaggle Gym Exercise Data](https://www.kaggle.com/datasets/niharika41298/gym-exercise-data), [Free Exercise DB](https://github.com/yuhonas/free-exercise-db)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1babe07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required libraries\n",
    "!pip install transformers datasets huggingface_hub kaggle pandas --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a019539d",
   "metadata": {},
   "source": [
    "## Load Secrets\n",
    "- Upload your Hugging Face token (for model push) and Kaggle API key (for dataset download) as files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a8b12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "uploaded = files.upload()  # Upload 'hf_token.txt' and 'kaggle.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd15c297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Hugging Face and Kaggle credentials\n",
    "import os\n",
    "from google.colab import userdata\n",
    "from huggingface_hub import login\n",
    "login(userdata.get('HF_TOKEN'))\n",
    "!mkdir -p ~/.kaggle; mv kaggle.json ~/.kaggle/; chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f09d46",
   "metadata": {},
   "source": [
    "## Download Datasets\n",
    "- Hugging Face: onurSakar/GYM-Exercise\n",
    "- Kaggle: niharika41298/gym-exercise-data\n",
    "- GitHub: yuhonas/free-exercise-db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c8ea80",
   "metadata": {},
   "source": [
    "## 1. Load & Preprocess Datasets\n",
    "- Download and load all external datasets (Hugging Face, Kaggle, GitHub).\n",
    "- Map all data to AthenAI DTO format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d78417",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "dataset_hf = load_dataset('onurSakar/GYM-Exercise')\n",
    "!kaggle datasets download -d niharika41298/gym-exercise-data --unzip\n",
    "!git clone https://github.com/yuhonas/free-exercise-db.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863385e5",
   "metadata": {},
   "source": [
    "## Explore & Normalize Data\n",
    "- Map external formats to AthenAI DTOs (see backend structure)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e54a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Load Kaggle CSV and inspect columns\n",
    "df_kaggle = pd.read_csv('megaGymDataset.csv')\n",
    "print('Columns:', df_kaggle.columns.tolist())\n",
    "df_kaggle.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fdc4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show sample from GitHub exercise dataset (free-exercise-db)\n",
    "import json\n",
    "with open('free-exercise-db/dist/exercises.json') as f:\n",
    "    exercises_github = json.load(f)\n",
    "print('Number of exercises:', len(exercises_github))\n",
    "print('Sample exercise:')\n",
    "print(json.dumps(exercises_github[0], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d98e5a5",
   "metadata": {},
   "source": [
    "## Define App-Specific DTOs\n",
    "- Use AthenAI backend DTOs for exercises, equipment, muscular groups, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3523146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example DTO structure (Python dict, based on Go DTOs)\n",
    "athenai_exercise_dto = {\n",
    "    'id': None,\n",
    "    'name': '',\n",
    "    'description': '',\n",
    "    'equipment': [],\n",
    "    'muscular_groups': [],\n",
    "    'deleted_at': None\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5edab5f4",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "- Convert all datasets to AthenAI DTO format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60cb1e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map Kaggle and GitHub exercise data to AthenAI DTO format and combine\n",
    "def map_kaggle_to_dto(row):\n",
    "    return {\n",
    "        'id': row['Unnamed: 0'] if not pd.isna(row['Unnamed: 0']) else None,\n",
    "        'name': row['Title'] if not pd.isna(row['Title']) else '',\n",
    "        'description': row['Desc'] if not pd.isna(row['Desc']) else '',\n",
    "        'equipment': [row['Equipment']] if not pd.isna(row['Equipment']) else [],\n",
    "        'muscular_groups': [row['BodyPart']] if not pd.isna(row['BodyPart']) else [],\n",
    "        'deleted_at': None\n",
    "    }\n",
    "dto_kaggle = df_kaggle.apply(map_kaggle_to_dto, axis=1).tolist()\n",
    "\n",
    "def map_github_to_dto(exercise):\n",
    "    return {\n",
    "        'id': exercise.get('id', None),\n",
    "        'name': exercise.get('name', ''),\n",
    "        'description': ' '.join(exercise.get('instructions', [])),\n",
    "        'equipment': [exercise['equipment']] if exercise.get('equipment') else [],\n",
    "        'muscular_groups': exercise.get('primaryMuscles', []) + exercise.get('secondaryMuscles', []),\n",
    "        'deleted_at': None\n",
    "    }\n",
    "dto_github = [map_github_to_dto(ex) for ex in exercises_github]\n",
    "\n",
    "# Hugging Face fitness dataset is loaded for context only, not mapped to DTOs\n",
    "\n",
    "# Combine Kaggle and GitHub sources\n",
    "all_exercises_dto = dto_kaggle + dto_github\n",
    "print(f'Total mapped exercises: {len(all_exercises_dto)}')\n",
    "print('Sample mapped exercise:', all_exercises_dto[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b850e16a",
   "metadata": {},
   "source": [
    "## Prepare Training Data\n",
    "- Input: user context, goal, template type\n",
    "- Output: workout DTO (list of exercises, sets, reps, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095ed77d",
   "metadata": {},
   "source": [
    "## 2. Training Setup\n",
    "- Format training examples for model input/output.\n",
    "- Set up model, tokenizer, and training arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24cd6ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build multiple diverse training examples for the model\n",
    "user_contexts = [\n",
    "    {\n",
    "        'description': 'Recovering from knee surgery, wants to regain strength and mobility.',\n",
    "        'training_phase': 'rehabilitation',\n",
    "        'motivation': 'return to sports',\n",
    "        'special_situation': 'leg limitation'\n",
    "    },\n",
    "    {\n",
    "        'description': 'Busy professional aiming for general fitness and stress relief.',\n",
    "        'training_phase': 'maintenance',\n",
    "        'motivation': 'reduce stress',\n",
    "        'special_situation': ''\n",
    "    },\n",
    "    {\n",
    "        'description': 'Young athlete preparing for a competition, needs endurance.',\n",
    "        'training_phase': 'pre-competition',\n",
    "        'motivation': 'win race',\n",
    "        'special_situation': ''\n",
    "    },\n",
    "    {\n",
    "        'description': 'Middle-aged person with back operation, wants to lose weight safely.',\n",
    "        'training_phase': 'weight loss',\n",
    "        'motivation': 'improve health',\n",
    "        'special_situation': 'back operation'\n",
    "    }\n",
    " ]\n",
    "\n",
    "workout_templates = [\n",
    "    {\n",
    "        'name': 'Lower Body Rehab',\n",
    "        'description': 'Safe lower body exercises for rehabilitation.',\n",
    "        'difficulty_level': 'beginner',\n",
    "        'estimated_duration_minutes': 45,\n",
    "        'target_audience': 'rehabilitation',\n",
    "        'blocks': [\n",
    "            {\n",
    "                'block_name': 'Warmup',\n",
    "                'block_type': 'warmup',\n",
    "                'block_order': 1,\n",
    "                'exercise_count': 2,\n",
    "                'estimated_duration_minutes': 10,\n",
    "                'instructions': 'Gentle mobility and activation.',\n",
    "                'exercises': all_exercises_dto[:2]\n",
    "            },\n",
    "            {\n",
    "                'block_name': 'Main Block',\n",
    "                'block_type': 'main',\n",
    "                'block_order': 2,\n",
    "                'exercise_count': 3,\n",
    "                'estimated_duration_minutes': 25,\n",
    "                'instructions': 'Controlled strength movements.',\n",
    "                'exercises': all_exercises_dto[2:5]\n",
    "            },\n",
    "            {\n",
    "                'block_name': 'Cool Down',\n",
    "                'block_type': 'cooldown',\n",
    "                'block_order': 3,\n",
    "                'exercise_count': 1,\n",
    "                'estimated_duration_minutes': 10,\n",
    "                'instructions': 'Stretch and relax.',\n",
    "                'exercises': all_exercises_dto[5:6]\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        'name': 'Quick Office Fitness',\n",
    "        'description': 'Short, equipment-free routine for busy professionals.',\n",
    "        'difficulty_level': 'beginner',\n",
    "        'estimated_duration_minutes': 20,\n",
    "        'target_audience': 'general_fitness',\n",
    "        'blocks': [\n",
    "            {\n",
    "                'block_name': 'Warmup',\n",
    "                'block_type': 'warmup',\n",
    "                'block_order': 1,\n",
    "                'exercise_count': 1,\n",
    "                'estimated_duration_minutes': 5,\n",
    "                'instructions': 'Light stretching.',\n",
    "                'exercises': all_exercises_dto[6:7]\n",
    "            },\n",
    "            {\n",
    "                'block_name': 'Main Block',\n",
    "                'block_type': 'main',\n",
    "                'block_order': 2,\n",
    "                'exercise_count': 2,\n",
    "                'estimated_duration_minutes': 10,\n",
    "                'instructions': 'Bodyweight exercises.',\n",
    "                'exercises': all_exercises_dto[7:9]\n",
    "            },\n",
    "            {\n",
    "                'block_name': 'Cool Down',\n",
    "                'block_type': 'cooldown',\n",
    "                'block_order': 3,\n",
    "                'exercise_count': 1,\n",
    "                'estimated_duration_minutes': 5,\n",
    "                'instructions': 'Breathing and relaxation.',\n",
    "                'exercises': all_exercises_dto[9:10]\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        'name': 'Endurance Builder',\n",
    "        'description': 'Cardio-focused template for athletes.',\n",
    "        'difficulty_level': 'intermediate',\n",
    "        'estimated_duration_minutes': 60,\n",
    "        'target_audience': 'endurance',\n",
    "        'blocks': [\n",
    "            {\n",
    "                'block_name': 'Warmup',\n",
    "                'block_type': 'warmup',\n",
    "                'block_order': 1,\n",
    "                'exercise_count': 2,\n",
    "                'estimated_duration_minutes': 10,\n",
    "                'instructions': 'Dynamic stretching.',\n",
    "                'exercises': all_exercises_dto[10:12]\n",
    "            },\n",
    "            {\n",
    "                'block_name': 'Cardio Block',\n",
    "                'block_type': 'cardio',\n",
    "                'block_order': 2,\n",
    "                'exercise_count': 4,\n",
    "                'estimated_duration_minutes': 40,\n",
    "                'instructions': 'High intensity intervals.',\n",
    "                'exercises': all_exercises_dto[12:16]\n",
    "            },\n",
    "            {\n",
    "                'block_name': 'Cool Down',\n",
    "                'block_type': 'cooldown',\n",
    "                'block_order': 3,\n",
    "                'exercise_count': 1,\n",
    "                'estimated_duration_minutes': 10,\n",
    "                'instructions': 'Static stretching.',\n",
    "                'exercises': all_exercises_dto[16:17]\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        'name': 'Safe Weight Loss',\n",
    "        'description': 'Low-impact template for weight loss and back safety.',\n",
    "        'difficulty_level': 'beginner',\n",
    "        'estimated_duration_minutes': 30,\n",
    "        'target_audience': 'weight_loss',\n",
    "        'blocks': [\n",
    "            {\n",
    "                'block_name': 'Warmup',\n",
    "                'block_type': 'warmup',\n",
    "                'block_order': 1,\n",
    "                'exercise_count': 1,\n",
    "                'estimated_duration_minutes': 5,\n",
    "                'instructions': 'Gentle stretching.',\n",
    "                'exercises': all_exercises_dto[17:18]\n",
    "            },\n",
    "            {\n",
    "                'block_name': 'Main Block',\n",
    "                'block_type': 'main',\n",
    "                'block_order': 2,\n",
    "                'exercise_count': 2,\n",
    "                'estimated_duration_minutes': 20,\n",
    "                'instructions': 'Low-impact movements.',\n",
    "                'exercises': all_exercises_dto[18:20]\n",
    "            },\n",
    "            {\n",
    "                'block_name': 'Cool Down',\n",
    "                'block_type': 'cooldown',\n",
    "                'block_order': 3,\n",
    "                'exercise_count': 1,\n",
    "                'estimated_duration_minutes': 5,\n",
    "                'instructions': 'Relaxation and breathing.',\n",
    "                'exercises': all_exercises_dto[20:21]\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    " ]\n",
    "\n",
    "# Pair each user context with a matching workout template for training\n",
    "train_examples = [\n",
    "    {'input': user_contexts[i], 'output': workout_templates[i]} for i in range(len(user_contexts))\n",
    " ]\n",
    "print('Sample training examples for model:')\n",
    "import pprint; pprint.pprint(train_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf609807",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Synthetic Training Example Generator: Consistent Block Structure\n",
    "import random\n",
    "def get_exercises_by_type(exercises, block_type):\n",
    "    # Example mapping: you may need to refine this based on your DTOs\n",
    "    type_map = {\n",
    "        'warmup': ['Warmup', 'Mobility', 'Stretch', 'Activation', 'Light'],\n",
    "        'main': ['Strength', 'Power', 'Compound', 'Bodyweight', 'Resistance'],\n",
    "        'cardio': ['Cardio', 'Aerobic', 'Interval', 'Endurance'],\n",
    "        'cooldown': ['Cool Down', 'Stretch', 'Relaxation', 'Breathing']\n",
    "    }\n",
    "    keywords = type_map.get(block_type, [])\n",
    "    return [ex for ex in exercises if any(kw.lower() in ex.get('description','').lower() or kw.lower() in ex.get('name','').lower() for kw in keywords)]\n",
    "\n",
    "def generate_random_workout_template(exercises):\n",
    "    blocks = []\n",
    "    # Randomize block types and counts for more variation\n",
    "    block_defs = [\n",
    "        {'block_type': 'warmup', 'count': random.randint(1,3), 'duration': random.randint(5,15), 'instructions': random.choice(['Gentle mobility and activation.','Light stretching.','Dynamic warmup.'])},\n",
    "        {'block_type': random.choice(['main','cardio']), 'count': random.randint(2,5), 'duration': random.randint(15,40), 'instructions': random.choice(['Strength movements.','High intensity intervals.','Bodyweight exercises.','Cardio focus.'])},\n",
    "        {'block_type': 'cooldown', 'count': random.randint(1,2), 'duration': random.randint(5,15), 'instructions': random.choice(['Stretch and relax.','Breathing and relaxation.','Static stretching.'])}\n",
    "    ]\n",
    "    for i, block_def in enumerate(block_defs):\n",
    "        block_exs = get_exercises_by_type(exercises, block_def['block_type'])\n",
    "        selected = random.sample(block_exs, min(block_def['count'], len(block_exs))) if block_exs else []\n",
    "        blocks.append({\n",
    "            'block_name': block_def['block_type'].capitalize(),\n",
    "            'block_type': block_def['block_type'],\n",
    "            'block_order': i+1,\n",
    "            'exercise_count': len(selected),\n",
    "            'estimated_duration_minutes': block_def['duration'],\n",
    "            'instructions': block_def['instructions'],\n",
    "            'exercises': selected\n",
    "        })\n",
    "    return {\n",
    "        'name': f\"Randomized Workout {random.randint(1000,9999)}\",\n",
    "        'description': random.choice(['Auto-generated workout for training.','Personalized workout plan.','Custom fitness routine.']),\n",
    "        'difficulty_level': random.choice(['beginner','intermediate','advanced']),\n",
    "        'estimated_duration_minutes': sum(b['estimated_duration_minutes'] for b in blocks),\n",
    "        'target_audience': random.choice(['rehabilitation','general_fitness','endurance','weight_loss','athlete','office_worker']),\n",
    "        'blocks': blocks\n",
    "    }\n",
    "\n",
    "# Generate synthetic training examples (step 1)\n",
    "synthetic_train_examples = []\n",
    "for _ in range(1000):\n",
    "    user_ctx = {\n",
    "        'description': random.choice([\n",
    "            'Recovering from injury, needs gentle start.',\n",
    "            'Wants to build muscle.',\n",
    "            'Looking for weight loss.',\n",
    "            'Training for a marathon.',\n",
    "            'Needs stress relief.',\n",
    "            'Preparing for competition.',\n",
    "            'Improving general fitness.',\n",
    "            'Returning to sports after break.',\n",
    "            'Busy professional with limited time.',\n",
    "            'Middle-aged person with back operation.'\n",
    "        ]),\n",
    "        'training_phase': random.choice(['rehabilitation','maintenance','pre-competition','weight loss','general','strength','cardio']),\n",
    "        'motivation': random.choice(['return to sports','reduce stress','win race','improve health','improve fitness','lose weight','gain muscle','increase endurance']),\n",
    "        'special_situation': random.choice(['leg limitation','back operation','none','injury','time constraint',''])\n",
    "    }\n",
    "    workout = generate_random_workout_template(all_exercises_dto)\n",
    "    synthetic_train_examples.append({'input': user_ctx, 'output': workout})\n",
    "print(f\"Generated {len(synthetic_train_examples)} synthetic training examples.\")\n",
    "# Step 2: Shuffle and mix with curated examples before training\n",
    "# (Do this in the training cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90aee1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell intentionally left blank. Hugging Face mapped exercises are not added to training examples. Only curated and synthetic examples are used for training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fdf088f",
   "metadata": {},
   "source": [
    "## Model Loading & Training\n",
    "- Load flan-t5-base, fine-tune with Hugging Face Trainer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea405e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# 1. Imports\n",
    "# ===============================\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, Trainer, TrainingArguments, DataCollatorForSeq2Seq\n",
    "from datasets import Dataset\n",
    "import torch, json, random\n",
    "\n",
    "# Use GPU if available\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# ===============================\n",
    "# 2. Load base model + tokenizer\n",
    "# ===============================\n",
    "model_name = \"a-albiol/AthenAI\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(device)\n",
    "\n",
    "# ===============================\n",
    "# 3. Combine + shuffle dataset\n",
    "# ===============================\n",
    "all_train_examples = train_examples + synthetic_train_examples\n",
    "random.shuffle(all_train_examples)\n",
    "\n",
    "def format_example(example):\n",
    "    input_text = f\"Description: {example['input']['description']} | Phase: {example['input']['training_phase']} | Motivation: {example['input']['motivation']} | Special: {example['input']['special_situation']}\"\n",
    "    # ⬇ You might want to start with a simpler target than full JSON first\n",
    "    output_text = json.dumps(example['output'], ensure_ascii=False)\n",
    "    return {'input_text': input_text, 'output_text': output_text}\n",
    "\n",
    "dataset = Dataset.from_list([format_example(e) for e in all_train_examples])\n",
    "\n",
    "# ===============================\n",
    "# 4. Train/Validation split\n",
    "# ===============================\n",
    "dataset = dataset.train_test_split(test_size=0.1, seed=42)\n",
    "train_dataset = dataset['train']\n",
    "eval_dataset = dataset['test']\n",
    "\n",
    "# ===============================\n",
    "# 5. Preprocessing (Tokenization)\n",
    "# ===============================\n",
    "def preprocess_function(examples):\n",
    "    model_inputs = tokenizer(\n",
    "        examples['input_text'],\n",
    "        max_length=256,\n",
    "        truncation=True,\n",
    "    )\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(\n",
    "            examples['output_text'],\n",
    "            max_length=512,\n",
    "            truncation=True,\n",
    "        )\n",
    "    model_inputs['labels'] = labels['input_ids']\n",
    "    return model_inputs\n",
    "\n",
    "tokenized_train = train_dataset.map(preprocess_function, batched=True)\n",
    "tokenized_eval  = eval_dataset.map(preprocess_function, batched=True)\n",
    "\n",
    "# ===============================\n",
    "# 6. Data Collator\n",
    "# ===============================\n",
    "data_collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer,\n",
    "    model=model,\n",
    "    label_pad_token_id=-100  # ignore padding tokens in loss\n",
    ")\n",
    "\n",
    "# ===============================\n",
    "# 7. Training Arguments\n",
    "# ===============================\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./athenai-finetune',\n",
    "    evaluation_strategy=\"epoch\",  # evaluate after each epoch\n",
    "    save_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    gradient_accumulation_steps=2,\n",
    "    num_train_epochs=5,\n",
    "    fp16=True,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "# ===============================\n",
    "# 8. Trainer\n",
    "# ===============================\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_eval,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "# ===============================\n",
    "# 9. Train\n",
    "# ===============================\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf4b172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug: Print a few tokenized training examples to inspect input/output and tokenization\n",
    "print('--- Raw training example ---')\n",
    "for i in range(3):\n",
    "    print('Input:', all_train_examples[i]['input'])\n",
    "    print('Output:', all_train_examples[i]['output'])\n",
    "    print()\n",
    "\n",
    "print('--- Tokenized training example ---')\n",
    "for i in range(3):\n",
    "    example = format_example(all_train_examples[i])\n",
    "    tokenized = preprocess_function(example)\n",
    "    print('Input text:', example['input_text'])\n",
    "    print('Output text:', example['output_text'])\n",
    "    print('Input token ids:', tokenized['input_ids'])\n",
    "    print('Label token ids:', tokenized['labels'])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0f6ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect a batch from the tokenized training dataset to check for padding, label, and attention mask issues\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 4\n",
    "loader = DataLoader(tokenized_train, batch_size=batch_size)\n",
    "batch = next(iter(loader))\n",
    "\n",
    "print('--- Batch keys ---')\n",
    "print(batch.keys())\n",
    "\n",
    "for i in range(batch_size):\n",
    "    print(f'\\n--- Example {i+1} ---')\n",
    "    print('Input IDs:', batch['input_ids'][i])\n",
    "    print('Labels:', batch['labels'][i])\n",
    "    if 'attention_mask' in batch:\n",
    "        print('Attention mask:', batch['attention_mask'][i])\n",
    "    # Decode input and label for inspection\n",
    "    print('Decoded input:', tokenizer.decode(batch['input_ids'][i], skip_special_tokens=True))\n",
    "    print('Decoded label:', tokenizer.decode(batch['labels'][i], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602ae109",
   "metadata": {},
   "source": [
    "## Evaluation & Sample Generation\n",
    "- Generate sample workouts from user context using the fine-tuned model.\n",
    "- Evaluate model outputs for accuracy and structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018141e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model: generate workouts for real user contexts and compare to expected templates\n",
    "import pprint\n",
    "def generate_workout(user_context):\n",
    "    input_text = f\"Description: {user_context['description']} | Phase: {user_context['training_phase']} | Motivation: {user_context['motivation']} | Special: {user_context['special_situation']}\"\n",
    "    inputs = tokenizer(input_text, return_tensors='pt').to(device)\n",
    "    outputs = model.generate(**inputs, max_length=512)\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# Evaluate on all training examples\n",
    "for i, example in enumerate(train_examples):\n",
    "    print(f\"\\n=== Example {i+1} ===\")\n",
    "    print(\"User Context:\")\n",
    "    pprint.pprint(example['input'])\n",
    "    print(\"Expected Workout Template:\")\n",
    "    pprint.pprint(example['output'])\n",
    "    print(\"Model Generated Workout:\")\n",
    "    generated = generate_workout(example['input'])\n",
    "    print(generated)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e8b5b2",
   "metadata": {},
   "source": [
    "## Save & Push Model to Hugging Face\n",
    "- Save model and push to a-albiol/AthenAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d429c357",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "from google.colab import userdata\n",
    "\n",
    "login(userdata.get('HF_TOKEN'))  # Replace ACCESS_TOKEN with your actual token\n",
    "\n",
    "# Upload model and tokenizer to Hub with name 'AthenAI'\n",
    "model.push_to_hub(\"AthenAI\")\n",
    "tokenizer.push_to_hub(\"AthenAI\")\n",
    "\n",
    "print(\"Model and tokenizer successfully uploaded to Hugging Face Hub as 'AthenAI'.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
